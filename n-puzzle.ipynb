{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from random import choice\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "from numpy import array_str\n",
    "from heapq import heappop, heappush"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def action struct\n",
    "action = namedtuple('Action', ['pos1', 'pos2'])\n",
    "\n",
    "PUZZLE_DIM = 5 \n",
    "RANDOMIZE_STEPS = 10_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of available actions\n",
    "def available_actions(state: np.ndarray) -> list['Action']:\n",
    "    x, y = [int(_[0]) for _ in np.where(state == 0)] \n",
    "    actions = []\n",
    "    if x > 0: # can go up\n",
    "        actions.append(action((x, y), (x - 1, y)))\n",
    "    if x < PUZZLE_DIM - 1:  # can go down\n",
    "        actions.append(action((x, y), (x + 1, y)))\n",
    "    if y > 0:  # can go left\n",
    "        actions.append(action((x, y), (x, y - 1)))\n",
    "    if y < PUZZLE_DIM - 1:  # can go right\n",
    "        actions.append(action((x, y), (x, y + 1)))\n",
    "    return actions\n",
    "\n",
    "def do_action(state: np.ndarray, action: 'Action') -> np.ndarray:\n",
    "    new_state = state.copy()\n",
    "    new_state[action.pos1], new_state[action.pos2] = new_state[action.pos2], new_state[action.pos1]\n",
    "    return new_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate the manhattan distance (distance between the goal and the current state)\n",
    "def manhattan_distance(state: np.ndarray) -> int:\n",
    "    distance = 0\n",
    "    for value in range(1, PUZZLE_DIM ** 2):\n",
    "        x, y = np.where(state == value)\n",
    "        x, y = int(x[0]), int(y[0])\n",
    "        goal_x, goal_y = divmod(value, PUZZLE_DIM)\n",
    "        distance += abs(x - goal_x) + abs(y - goal_y)\n",
    "    return distance\n",
    "\n",
    "# bool function that return true if the state is the goal\n",
    "def goal_function( state ,goal ):\n",
    "    label = np.array_equal(state, goal)\n",
    "    if(label):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def a_star_search(initial_state: np.ndarray, goal: np.ndarray) -> list['Action']:\n",
    "    frontier = [(manhattan_distance(initial_state), 0, tuple(initial_state.flatten()), [])]\n",
    "    visited = set()\n",
    "    \n",
    "    while frontier:\n",
    "        _, real_cost, state_tuple, path = heappop(frontier)\n",
    "        \n",
    "        state = np.array(state_tuple).reshape(PUZZLE_DIM, PUZZLE_DIM)\n",
    "        \n",
    "        if goal_function(state, goal):\n",
    "            return path\n",
    "        \n",
    "        if state_tuple in visited:\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        visited.add(state_tuple)\n",
    "        \n",
    "        for act in available_actions(state):\n",
    "            new_state = do_action(state, act)\n",
    "            new_path = path + [act]\n",
    "            new_real_cost = real_cost + 1\n",
    "            new_est_cost = new_real_cost + manhattan_distance(new_state)\n",
    "            heappush(frontier, (new_est_cost, new_real_cost, tuple(new_state.flatten()), new_path))\n",
    "    \n",
    "    # No solution found\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "PUZZLE_DIM = 3\n",
    "action = namedtuple('Action', ['pos1', 'pos2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 0]\n",
      " [7 8 6]]\n",
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 0]]\n"
     ]
    }
   ],
   "source": [
    "RANDOMIZE_STEPS = 100_000\n",
    "state = np.array([i for i in range(1, PUZZLE_DIM**2)] + [0]).reshape((PUZZLE_DIM, PUZZLE_DIM))\n",
    "goal = state.copy()\n",
    "for r in tqdm(range(RANDOMIZE_STEPS), desc='Randomizing'):\n",
    "    state = do_action(state, choice(available_actions(state)))\n",
    "tmp = goal[1,2]\n",
    "goal[1,2] = goal[2,2]\n",
    "goal[2,2] = tmp\n",
    "print(goal)\n",
    "print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[Action(pos1=(2, 2), pos2=(1, 2))]\n"
     ]
    }
   ],
   "source": [
    "solution = a_star_search( state, goal)\n",
    "print(len(solution))\n",
    "print(solution)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
